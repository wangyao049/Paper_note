### 1. Matching Networks for One Shot Learning
[论文地址](https://arxiv.org/pdf/1606.04080.pdf)

#### 算法思想:
- **Observation 1:** 对于深度学习方法，数据增强和正则化可以减轻小样本学习中的过拟合问题，但是并没有解决。深度学习需要大量的参数权重更新，使得训练速度很慢。(Data augmentation and regularization techniques alleviate overfitting in low data regimes, but do not solve it. Furthermore, learning is slow and based on large datasets, requiring many weight updates using sgd.)
- **Observation 2:** 无参模型（例如KNN）不会出现这些问题，但是这类模型需要手动选择度量方法。(non-parametric models do not require any training but performance depends on the chosen metric:e.g. L2 distance)
- **Core idea:** Lets train a fully end-to-end nearest neighbor classifier!

![](https://github.com/wangyao049/Paper_note/blob/master/image/7.png)

#### 训练方法：
- As the authors amusingly point out in the conclusion "one-shot learning is much easier if you train the network to do one-shot learning". Therefore, we want the test-time protocol (given N novel classes with only k examples each (e.g. k = 1 or 5), predict new instances to one of N classes) to exactly match the training time protocol. 
- To create each "episode" of training from a dataset of examples then:
    - 将训练集中的所有标签的集合作为Task T (例如选择五个标签，每类最多五张图片)
    - 从Task T中采样一个标签集L(例如{cats, dogs})，然后用L采样出支撑集S和batch B，用于计算网络损失。
    
#### 模型：
**主要目标是构建一个可微的 nearest neighbor**
![]()
- 其中，S={xi,yi}是support set(支撑集)，{x/hat, y/hat}是 test set(测试集)。**a**是一个kernel,计算x/hat与xi的相似程度，并于相对应的one-hot标签yi加权混合得到y/hat。
- Now, we're going to embed both the training examples x_i and the test example \hat{x}, and we'll interpret their inner products (or here a cosine similarity) as the "match", and pass that through a softmax to get normalized mixing weights so they add up to 1. 
![]()
其中，**c**是余弦相似度。

- **Embedding the training examples** This (the function g) is a bidirectional LSTM(双向LSTM) over the examples
- **Embedding the test samples** LSTM with attention where the input at each time step is constant (f'(\hat{x}), an encoding of the test example all by itself) and the hidden state is a function of previous hidden state but also a concatenated readout vector r, which we obtain by attending over the encoded training examples (encoded with g from above).
