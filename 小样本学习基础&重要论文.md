### 小样本学习领域重要的论文列表：（按照时间顺序）
- Siamese neural networks for one-shot image recognition. -ICML 2015
- Matching Networks for one shot learning. -NIPS 2016
- Prototypical networks for few-shot learning. -NIPS 2017
- Model-agnostic meta-learning for fast adaptation of deep networks. -ICML 2017
- Learning to Compare: Relation Network for Few-Shot Learning. -CVPR 2018
------
### 1. Siamese neural networks for one-shot image recognition 孪生网络
[论文地址]()
[代码](https://github.com/Goldesel23/Siamese-Networks-for-One-Shot-Learning)

[很全面的论文解析](https://sorenbouma.github.io/blog/oneshot/)

#### 什么是孪生网络？
- 两个共享权值的神经网络就是siamese network，如果不共享权值，叫做pseudo-siamese network(伪孪生神经网络，两边可以是不同的神经网络，例如一个是lstm,一个是cnn)。
- **孪生神经网络的用途**：简单来说，衡量两个输入的相似程度。孪生神经网络有两个输入（Input1 and Input2）,将两个输入feed进入两个神经网络（Network1 and Network2），这两个神经网络分别将输入映射到新的空间，形成输入在新的空间中的表示。通过Loss的计算，评价两个输入的相似度。
- **适用场景**：孪生神经网络用于处理两个输入"比较类似"的情况。伪孪生神经网络适用于处理两个输入"有一定差别"的情况。比如，我们要计算两个句子或者词汇的语义相似度，使用siamese network比较适合；如果验证标题与正文的描述是否一致（标题和正文长度差别很大），或者文字是否描述了一幅图片（一个是图片，一个是文字），就应该使用pseudo-siamese network。也就是说，要根据具体的应用，判断应该使用哪一种结构，哪一种Loss。
- **损失函数的选择**：Softmax当然是一种好的选择，但不一定是最优选择，即使是在分类问题中。传统的siamese network使用Contrastive Loss。损失函数还有更多的选择，siamese network的初衷是计算两个输入的相似度,。左右两个神经网络分别将输入转换成一个"向量"，在新的空间中，通过判断cosine距离就能得到相似度了。Cosine是一个选择，exp function也是一种选择，欧式距离什么的都可以，训练的目标是让两个相似的输入距离尽可能的小，两个不同类别的输入距离尽可能的大。

#### 孪生网络用于one-shot Learning

![](https://github.com/wangyao049/Paper_note/blob/master/image/13.png)

- 算法思想：使用两个网络(left/right network)分别对支撑集和测试集图片进行特征提取，然后计算两个特征向量的L1相似度，该相似度作为线性分类器（sigmoid）的输入，并输出两者属于同一类的预测值[0,1]。在网络优化过程中，同类别图片的预测值为1，不同类别为0。When it does a one-shot task, the siamese net simply classifies the test image as whatever image in the support set it thinks is most similar to the test image。
-----

### 2. Matching Networks for One Shot Learning 匹配网络
[论文地址](https://arxiv.org/pdf/1606.04080.pdf)
[代码](https://github.com/gitabcworld/MatchingNetworks)

#### 算法思想:
- **Observation 1:** 对于深度学习方法，数据增强和正则化可以减轻小样本学习中的过拟合问题，但是并没有解决。深度学习需要大量的参数权重更新，使得训练速度很慢。(Data augmentation and regularization techniques alleviate overfitting in low data regimes, but do not solve it. Furthermore, learning is slow and based on large datasets, requiring many weight updates using sgd.)
- **Observation 2:** 无参模型（例如KNN）不会出现这些问题，但是这类模型需要手动选择度量方法。(non-parametric models do not require any training but performance depends on the chosen metric:e.g. L2 distance)
- **Core idea:** Lets train a fully end-to-end nearest neighbor classifier!

![](https://github.com/wangyao049/Paper_note/blob/master/image/7.png)

#### 训练方法：
- As the authors amusingly point out in the conclusion "one-shot learning is much easier if you train the network to do one-shot learning". Therefore, we want the test-time protocol (given N novel classes with only k examples each (e.g. k = 1 or 5), predict new instances to one of N classes) to exactly match the training time protocol. 
- To create each "episode" of training from a dataset of examples then:
    - 将训练集中的所有标签的集合作为Task T (例如选择五个标签，每类最多五张图片)
    - 从Task T中采样一个标签集L(例如{cats, dogs})，然后用L采样出支撑集S和batch B，用于计算网络损失。
    
#### 模型：
**主要目标是构建一个可微的 nearest neighbor**

![](https://github.com/wangyao049/Paper_note/blob/master/image/8.png)

- 其中，S={xi,yi}是support set(支撑集)，{x/hat, y/hat}是 test set(测试集)。**a**是一个kernel,计算x/hat与xi的相似程度，并于相对应的one-hot标签yi加权混合得到y/hat。
- Now, we're going to embed both the training examples x_i and the test example \hat{x}, and we'll interpret their inner products (or here a cosine similarity) as the "match", and pass that through a softmax to get normalized mixing weights so they add up to 1. 

![](https://github.com/wangyao049/Paper_note/blob/master/image/9.png)
其中，**c**是余弦相似度。

- **Embedding the training examples** This (the function g) is a bidirectional LSTM(双向LSTM) over the examples
- **Embedding the test samples** LSTM with attention where the input at each time step is constant (f'(\hat{x}), an encoding of the test example all by itself) and the hidden state is a function of previous hidden state but also a concatenated readout vector r, which we obtain by attending over the encoded training examples (encoded with g from above).
------
### 3. Prototypical networks for few-shot learning 原型网络
[论文地址](https://arxiv.org/pdf/1703.05175.pdf)
[代码](https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch)

#### 算法思想：
- 本文提出了一种可以用于few-shot learning的原形网络（prototypical networks）。该网络能识别出在训练过程中从未见过的新的类别，并且对于每个类别只需要很少的样例数据。
- 原形网络将每个类别中的样例数据映射到一个高维空间当中，并且计算他们的“均值”来表示为该类的原形（prototype）。
- 使用欧式距离作为距离度量，训练使得本类别数据到本类原形表示的距离为最近，到其他类原形表示的距离较远。测试时，对测试数据到各个类别的原形数据的距离做softmax，来判断测试数据的类别标签。
#### 模型：
原型网络为每个类别计算出一个原型，类别的原形表示Ck是对支持集中的所有的向量化样例数据取均值得到的。

![](https://github.com/wangyao049/Paper_note/blob/master/image/15.png)

在测试时，原形网络使用softmax作用在query向量点到Ck的距离。

![](https://github.com/wangyao049/Paper_note/blob/master/image/16.png)

训练过程是通过随机梯度下降法最小化目标函数：
![](https://github.com/wangyao049/Paper_note/blob/master/image/17.png)
其中k为训练样本的真实标签。训练的episode为随机从训练集中选择的一个类子集，从这些类子集中选择一些样例数据作为支持（support set）集，其剩余的作为查询（query set）集。
#### Zero-shot Learning
零样本学习不同于少样本学习，其meta-data向量Vk不是由训练集中的支持样本生成的，而是根据每个类的属性描述、原始数据等生成的。这些信息都是可以提取确定或者从原始数据中得到的。原形网络也能过灵活的转变成零样本学习，我们简单的定义Ck=gv（k）为一个meta-data向量。对于零样本学习和少样本学习详见下图：

![](https://github.com/wangyao049/Paper_note/blob/master/image/14.png)

注：当one-shot learning 的时候（每个类别只有一个样本），该方法等同于Matching network，只不过用的距离度量不一样，匹配网络用的是余弦距离，本文用的欧氏距离。

### 5. Learning to Compare: Relation Network for Few-Shot Learning 关系网络
[论文地址](https://arxiv.org/pdf/1711.06025.pdf)
[代码](https://github.com/floodsung/LearningToCompare_FSL)

### 算法思想：
本文提出了端对端的度量学习方法-关系网络（Relation Network），该方法与Matching Network和Prototypical networks类似,区别在于这两种方法使用了预定义的距离度量（例如欧氏距离，余弦距离），**而本文提出的方法通过神经网络自动学习出一个距离度量。**
![](https://github.com/wangyao049/Paper_note/blob/master/image/10.png)

- 关系网络包括两个模型：嵌入模块f 和关系模块g。如上图所示，是一个典型的 5way 1shot 的少样本学习问题，也就是我们要对 5 个新类别的物体进行识别，但是每一类物体我们只给出一个样本。上图中，最左侧的 5 张图片就是我们拥有的训练样本（一般称为 support set）而旁边的一个图片则是我们用来测试的样本（一般称为 testing set）。
- **我们先构造一个嵌入单元（embedding module）来提取每一张图片的特征信息，是什么特征我们不管，然后我们把要测试的图片特征和训练样本的图片特征连起来输入到关系单元（relation module）中做比较，然后我们根据比较的结果（relation score）来判断这个测试图片到底属于哪一个类。** 比如上图中测试图片是狗，那么它跟训练样本中狗的图片相似度比较高，那么我们就认为这个新的图片是狗。
- 那么怎么来训练这个网络呢？我们有一个拥有大量数据的训练集（training set），我们利用这个训练集来构造出和测试时类似的数据结构，也就是 sample set 和 query set 来模拟测试时的 support set 和 testing set。我们可以使用训练集来生成巨量的模拟任务，从而在 meta 层面上训练整个关系网络。**我们把输出的 relation score 看做是一个从 0 到 1 的数值。0 就代表极不相似，而 1 则代表完全相似。** 因此，我们就非常直接地采用平方差 MSE 作为网络训练的 loss。

![](https://github.com/wangyao049/Paper_note/blob/master/image/11.png)

从公式来看该问题是一个{0，1}分类问题，从概念上来看，该问题是预测图片相似度的回归问题。

### 为什么关系网络有效？
- 在少样本学习领域，我们的方法可以认为是一种基于度量（metric-based）的方法，但是我们的方法很不一样的一点，也是创新的一点在于我们完全使用神经网络来学习这种度量方式，并且使用元学习的训练方式。而一般的基于度量的方法都是人为的设计一种度量，比如最简单的欧式距离。显然，人为设计的方式总是有缺陷的，那么我们就想来看看，使用神经网络来学习的度量是不是能比人为设计的好。
- 因此，我们做了个小实验来印证这个想法。这个小实验是一个 2 维数据的比较实验。比如这样两个数据（1，2）和（-2，-1），这两个数据看起来是不相关的，但是它们在某一些状态下可能属于同一个类别。那么这种情况，其实传统的人为设计的度量方式实际上就失效了。我们只能通过神经网络去学习这种度量。所以像下图这样复杂的螺旋曲线关系数据情况，我们通过关系网络（relation network）可以学的不错，而人为度量则完全不行。

![](https://github.com/wangyao049/Paper_note/blob/master/image/12.png)

------
