### 小样本学习领域重要的论文列表：（按照时间顺序）
- Siamese neural networks for one-shot image recognition. -ICML 2015
- Matching Networks for one shot learning. -NIPS 2016
- Prototypical networks for few-shot learning. -NIPS 2017
- Model-agnostic meta-learning for fast adaptation of deep networks. -ICML 2017
- Learning to Compare: Relation Network for Few-Shot Learning. -CVPR 2018

### 1. Matching Networks for One Shot Learning
[论文地址](https://arxiv.org/pdf/1606.04080.pdf)
[代码](https://github.com/gitabcworld/MatchingNetworks)

#### 算法思想:
- **Observation 1:** 对于深度学习方法，数据增强和正则化可以减轻小样本学习中的过拟合问题，但是并没有解决。深度学习需要大量的参数权重更新，使得训练速度很慢。(Data augmentation and regularization techniques alleviate overfitting in low data regimes, but do not solve it. Furthermore, learning is slow and based on large datasets, requiring many weight updates using sgd.)
- **Observation 2:** 无参模型（例如KNN）不会出现这些问题，但是这类模型需要手动选择度量方法。(non-parametric models do not require any training but performance depends on the chosen metric:e.g. L2 distance)
- **Core idea:** Lets train a fully end-to-end nearest neighbor classifier!

![](https://github.com/wangyao049/Paper_note/blob/master/image/7.png)

#### 训练方法：
- As the authors amusingly point out in the conclusion "one-shot learning is much easier if you train the network to do one-shot learning". Therefore, we want the test-time protocol (given N novel classes with only k examples each (e.g. k = 1 or 5), predict new instances to one of N classes) to exactly match the training time protocol. 
- To create each "episode" of training from a dataset of examples then:
    - 将训练集中的所有标签的集合作为Task T (例如选择五个标签，每类最多五张图片)
    - 从Task T中采样一个标签集L(例如{cats, dogs})，然后用L采样出支撑集S和batch B，用于计算网络损失。
    
#### 模型：
**主要目标是构建一个可微的 nearest neighbor**

![](https://github.com/wangyao049/Paper_note/blob/master/image/8.png)

- 其中，S={xi,yi}是support set(支撑集)，{x/hat, y/hat}是 test set(测试集)。**a**是一个kernel,计算x/hat与xi的相似程度，并于相对应的one-hot标签yi加权混合得到y/hat。
- Now, we're going to embed both the training examples x_i and the test example \hat{x}, and we'll interpret their inner products (or here a cosine similarity) as the "match", and pass that through a softmax to get normalized mixing weights so they add up to 1. 

![](https://github.com/wangyao049/Paper_note/blob/master/image/9.png)
其中，**c**是余弦相似度。

- **Embedding the training examples** This (the function g) is a bidirectional LSTM(双向LSTM) over the examples
- **Embedding the test samples** LSTM with attention where the input at each time step is constant (f'(\hat{x}), an encoding of the test example all by itself) and the hidden state is a function of previous hidden state but also a concatenated readout vector r, which we obtain by attending over the encoded training examples (encoded with g from above).
------
### 5. Learning to Compare: Relation Network for Few-Shot Learning
[论文地址](https://arxiv.org/pdf/1711.06025.pdf)
[代码](https://github.com/floodsung/LearningToCompare_FSL)

### 算法思想：
本文提出了端对端的度量学习方法-关系网络（Relation Network），该方法与Matching Network和Prototypical networks类似,区别在于这两种方法使用了预定义的距离度量（例如欧氏距离，余弦距离），而本文提出的方法通过神经网络自动学习出一个距离度量。
![](https://github.com/wangyao049/Paper_note/blob/master/image/10.png)

- 关系网络包括两个模型：嵌入模块f 和关系模块g。如上图所示，是一个典型的 5way 1shot 的少样本学习问题，也就是我们要对 5 个新类别的物体进行识别，但是每一类物体我们只给出一个样本。上图中，最左侧的 5 张图片就是我们拥有的训练样本（一般称为 support set）而旁边的一个图片则是我们用来测试的样本（一般称为 testing set）。
- 我们先构造一个嵌入单元（embedding module）来提取每一张图片的特征信息，是什么特征我们不管，然后我们把要测试的图片特征和训练样本的图片特征连起来输入到关系单元（relation module）中做比较，然后我们根据比较的结果（relation score）来判断这个测试图片到底属于哪一个类。比如上图中测试图片是狗，那么它跟训练样本中狗的图片相似度比较高，那么我们就认为这个新的图片是狗。
- 那么怎么来训练这个网络呢？我们有一个拥有大量数据的训练集（training set），我们利用这个训练集来构造出和测试时类似的数据结构，也就是 sample set 和 query set 来模拟测试时的 support set 和 testing set。我们可以使用训练集来生成巨量的模拟任务，从而在 meta 层面上训练整个关系网络。我们把输出的 relation score 看做是一个从 0 到 1 的数值。0 就代表极不相似，而 1 则代表完全相似。因此，我们就非常直接地采用平方差 MSE 作为网络训练的 loss。

![](https://github.com/wangyao049/Paper_note/blob/master/image/11.png)

从公式来看该问题是一个{0，1}分类问题，从概念上来看，该问题是预测图片相似度的回归问题。

### 为什么关系网络有效？
- 在少样本学习领域，我们的方法可以认为是一种基于度量（metric-based）的方法，但是我们的方法很不一样的一点，也是创新的一点在于我们完全使用神经网络来学习这种度量方式，并且使用元学习的训练方式。而一般的基于度量的方法都是人为的设计一种度量，比如最简单的欧式距离。显然，人为设计的方式总是有缺陷的，那么我们就想来看看，使用神经网络来学习的度量是不是能比人为设计的好。
- 因此，我们做了个小实验来印证这个想法。这个小实验是一个 2 维数据的比较实验。比如这样两个数据（1，2）和（-2，-1），这两个数据看起来是不相关的，但是它们在某一些状态下可能属于同一个类别。那么这种情况，其实传统的人为设计的度量方式实际上就失效了。我们只能通过神经网络去学习这种度量。所以像下图这样复杂的螺旋曲线关系数据情况，我们通过关系网络（relation network）可以学的不错，而人为度量则完全不行。

![](https://github.com/wangyao049/Paper_note/blob/master/image/12.png)

------
