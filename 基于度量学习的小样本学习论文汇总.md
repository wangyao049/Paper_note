## 基于度量学习的小样本学习
--- 
### 1. Revisiting Local Descriptor based Image-to-Class Measure for Few-shot Learning
[论文地址](https://arxiv.org/abs/1903.12290?source=post_page)
[代码](https://github.com/WenbinLee/DN4.git)

![](https://github.com/wangyao049/-/blob/master/image/1.png)

- #### 算法思想：本文提出了一种使用基于局部描述子的image-to-class度量方法。基于NBNN(朴素贝叶斯最近邻算法)提出了DN4（Deep Nearest Neighbor Neural Network）模型,该模型分为两部分：
    - (1) **深度嵌入模型**，用来学习所有图像的深度局部描述子。该模型可以是任何CNN结构，只有卷积层，没有全连接层（因为提取的是局部特征，不是全局特征）,最后每张图片输出一张局部特征图（h\*w\*d tensor）; 
    - (2) **Image-to-class模型**，根据生成的局部特征，使用KNN计算query image和各种类别之间的image-to-class相似度（距离）。计算方法为，对于每张图片提取到的局部特征向量图q=[x1,x2,....,xm]中的每一个描述子xi,都在class c中找到其对应的 k-nearest neighbors，然后计算他们的相似度并累加，得到最后的image-to-class similarity between q and class c。（这里的相似度方程可以使用余弦相似度或者其他的距离方程）。相对于常规的图像分类问题，image-to-class的度量方法更适用于小样本分类，因为对大量数据搜索k近邻时计算复杂度很高。同时相对于传统的NBNN算法，本文使用CNN来提取局部特征而不是手工提取的特征。（这部分是没有可学习参数的，因此可以减轻过拟合问题）
    
- #### 问题：(1)为什么使用局部描述子(local descriptor)代替全局特征(image-level feature)？
    - **Image-level representation could significantly lose discriminative information.** If there are sufficient training samples, the subsequent learning process can somehow recover form  such a loss, still showing satisfactory classification performance. But, **when training samples are insufficient, this loss is unrecoveralbe and leads to poor classificaiton.** The existing methods usually pool the last convolutional feature maps(via the global average pooling or fully connected layer)to an image-level representaion for the final calssification. In this case, such an information loss will also occur and is unrecoverable.

- #### 问题：(2)为什么使用image-to-class相似度而不是image-to-image相似度？
    - This is because **image-to-image similarity does not generalize beyond training samples.** When the number of training samples is small, **a query image could be different from any training samples of the same class due to intra-class variation or background clutter.** Instead, and image-to-class measure should be used. 
    - Specifically, the local invariant features from all training samples in the same class are collected into one pool(属于同一个类别的所有训练数据的特征都放在一个池里). This measure evaluates the proximity(via nearest-neighbor search)of the local features of a query image to the pool of each class for classification(通过k近邻搜索找到与query image的特征最相近的类别池进行分类).
-----
### 2. Few-Shot Learning with Localization in Realistic Settings
[论文地址](https://arxiv.org/abs/1904.08502?source=post_page)

![](https://github.com/wangyao049/-/blob/master/image/2.png)

- #### 算法思想：
    - 传统的小样本学习方法使用的测试集均采用人为设定的均衡的数据样本，但是在真实环境下，存在数据不均衡，背景模糊以及细粒度图像等问题。因此，本文针对真实环境下的数据不平衡(class imbalance)，数据稀疏(data scarcity)，重尾分布(heavy-tailed distributions)等问题，提出了一种基于原型网络(Prototypical networks)的改进算法，从三个方面对原型网络进行改进。

- #### 改进：（1）为了解决数据不平衡问题，使用leave-one-out cross-validation的训练方法。(Batch Folding)
    - 传统方法是将每个batch中的图片划分为reference/query,进行训练。这里使用了留一法交叉验证，每一张图片都既是reference又是query。该方法提高了4个百分点准确率。
    - The entire batch is treated as reference images, and the contribution of each image is subtracted out from its corresponding prototype whenever it acts as a query. **Each image thus gets a combined, cleaner gradient, acting as both a reference and a query.** Furthermore, the number of query/reference images can be as high as the batch size.
    
- #### 改进：（2）为了解决当图片中前景过小和背景模糊时目标定位困难的问题，本文提出在分类之前先进行目标定位的网络结构。(Localization)
    - 无监督定位：区分前景和背景
    - 有监督定位：需要标注Bounding boxes（该方法提高了6个百分点准确率）
    
- #### 改进：（3）使用bilinear pooling（双线性池化）[Bilinear CNN Models for Fine-grained Visual Recognition](http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf) 提高细粒度图像分类的准确率。
    - This approach takes two feature maps(from e.g. a two-stream cnn) and computes the cross-covariance between them by performing a pixe-wise outer product(计算两个特征图的外积)before average pooling.
    - In this localizatio models, the predicted foreground and background maps act as the two stream.该方法提高了9%准确率。
-----
### 3. Dense Classification and Implanting for Few-Shot Learning
[论文地址](https://arxiv.org/abs/1903.05050?source=post_page)

- #### 算法思想：
    - 本文设计了一种将大的数据集中学习到的知识迁移到小的数据集的方法来完成小样本学习任务。主要的创新点为（1）设计了一种基于特征图的密集分类器；（2）在预训练好的模型上增添新的神经元进行学习，以适应新的数据集。
    - 论文将训练阶段分为两个阶段，第一个阶段，在较大规模的数据集上训练一个参数化的分类器即密集分类器，然后在第二阶段固定第一阶段Embedding模块的参数并引入新的神经元，通过测试集（数量较少的，训练集中未出现的类别）的支撑集(support set)对Embedding新引入的参数进行更新，以便于模型可以提取得到基于特定任务的特征信息。

- #### 密集预测(Dense Classification)
    - 首先，在小样本学习问题中，对于每一个输入图片X，经过Embedding网络以后会得到一个，r * d 的特征图，其中，r = (H * W)，d为提取得到特征图的通道数，已有的方法对Embedding网络提取出的特征的处理方式可以分为两大类，一种是直接通过一层或者是多层全连接层来预测属于图片属于哪一个类别，另一中则是直接通过global pooling 对特征图进行降维，得到一个d维的向量，然后进行预测。第一种方法虽然具有较强的判别性但是很容易过拟合，第二种则提取得到的特征在d不够大的情况下，往往会缺少判别性。因此作者提取了一种新的预测方法，具体如下图所示:
![](https://github.com/wangyao049/-/blob/master/image/3.png)

    - 作者根据训练集中数据的类别数C，设计C个d维度的类别向量，通过计算特征图每一个空间位置的向量与每一个类别向量的尺度余弦相似度（scaled cosine similarity）来判断当前位置的特征向量属于哪个类别。**通过约束每一个点的预测结果均为输入图片的类别，从而约束Embedding提取到的特征在每一个空间位置上都能最大化的反应出该图片的类别信息。**
    
- #### 迁移(Implanting)
    - 在较大的数据集上进行训练以后，则模型需要能够在拥有较少的的support 数据的情况下可以预测全新的新颖的类别的图片。在这一步，作者对上一步训练好的Embedding进行迁移，首先移除上一步学习到的类别向量，只保留Embedding模块的参数，并将其固定，引入新的神经元来对新的类别进行适应，具体的框架如下图所示：
![](https://github.com/wangyao049/-/blob/master/image/4.png)

    - 模型的上半部分即为粉红色模块即代表的是新增的神经元，通过新加入类别的support 集合的图片对改模型进行训练，不同的是在该阶段不加入新的类别变量，而是直接通过全局池化操作对提取到的特征进行降维，然后经过softmax函数直接得到预测结果，然后同样利用交叉熵损失对模型进行约束。
迁移完毕以后，即是对查询集（query set）的预测，作者这里采用和原型网络(prototypical network)相同的做法，提取出support 中每个类别的特征向量(r * d)，然后对特征向量进行全局池化以后得到d维的特征向量，将此特征向量作为类别向量，然后与第一阶段的做法相同，对于输入的查询集的每一张图片，提取出一个r∗dr * dr∗d的特征向量，然后预测每一个空间位置上的特征向量的类别，分到个数最多的空间位置向量的类别即为输入图片的类别。
-----
### 4. Variational Prototyping-Encoder:One-Shot Learning with Prototypical Images
[论文地址](https://arxiv.org/abs/1904.08482?source=post_page)

![](https://github.com/wangyao049/-/blob/master/image/5.png)

- #### 算法思想：本文针对路标和Logo的分类问题，提出了一种基于VAE算法的单样本学习方法-变分原型编码器（VPE），将标准图像化的图像作为原型。通过学习一个将真实图标映射到原型图标上的元学习任务来学习一种良好的表征。本文提出的算法主要包括两部分：训练阶段和测试阶段。
    - (1) VPE利用成对的真实图标/原型图标来学习一个可泛化的潜在空间，从而对新的数据（unseen）进行分类；
    - (2) VPE学习从真实图片到原型图片的转化，而不是使用预定义好的度量；
    - (3) VPE利用变分自编码器(VAE)的结构引用一个潜在特征空间，在该空间中，真实图片的特征紧密的聚集在它们所对应的原型图片特征的周围。

- #### 训练阶段(Training phase)
    - **编码器将真实图片(x)编码为潜在分布(z)，然后解码器将潜在分布解码为与真实图片想对应的原型图标(t)** ，简单来说，该方法相当于image-to-image translation 过程，由于真实图片通常包含了大量扰动（例如：背景模糊等），因此通过编码器将其转化为对应的标准化图片（VPE作为去噪网络）。网络的损失函数为：
    ![](https://github.com/wangyao049/-/blob/master/image/6.png)
    - 该公式中第一部分是重构损失和正则化项，KL divergence regularizes the latent space by encouraging the distribution of z follows the prior distribution.在本论文中，重构损失使用了binary cross entropy loss。
    
- #### 测试阶段(Testing phase)
    - The learned encoder is only used as a feature extractor. Given a novel class support set of prototypes, we initially extract their features from the encoder and store them in the support set.**(对新类别的原型图片提取特征并存储在支撑集里)**
    - When an input query is given, we extract its feature by the encoder and classify by NN clssification by retrieving the support set. The similarity can be meatured by Euclidean or Mahalanobis distances.**(提取query image的特征，在潜在空间中检索与其最接近的原型图片进行分类)**
    
- 注：该论文使用了数据增强(data augmentation)和空间变换网络(STN)提升分类准确率。
-----

